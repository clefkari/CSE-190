{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape, Dropout, LSTM, Activation, Input, Lambda, Flatten, Bidirectional\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.models import load_model\n",
    "from numpy.random import multinomial as randm\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Counts = Current Counts + Note Length % 16 ?\n",
    "\n",
    "def buildNotes():\n",
    "    \n",
    "    #print(\"In buildNotes()\")\n",
    "    \n",
    "    notes = []\n",
    "    noteLengths = []\n",
    "    \n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        \n",
    "        try:\n",
    "            midi = converter.parse(file)    \n",
    "            \n",
    "        except:\n",
    "            print(\"MIDI file %s failed to parse\" % file)\n",
    "            continue\n",
    "            \n",
    "        print(\"Parsing %s\" % file)\n",
    "        notesToParse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notesToParse = s2.parts[0].recurse()\n",
    "            print(\"Instrument Parts %d\" % len(s2.parts))\n",
    "            \n",
    "        except: # file has notes in a flat structure\n",
    "            notesToParse = midi.flat.notes\n",
    "            \n",
    "        # For each note in notesToParse (a stream of notes)\n",
    "            \n",
    "        for element in notesToParse:\n",
    "            \n",
    "            # Interesting parameters of notes that we may want to look at here.\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                noteLengths.append(str(float(element.quarterLength)))\n",
    "                \n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                noteLengths.append(str(float(element.quarterLength)))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "    pickle.dump(noteLengths, open('noteLengths.p', 'wb'))\n",
    "\n",
    "    return notes, noteLengths\n",
    "\n",
    "def prepareSeq(notes, noteLengths):\n",
    "\n",
    "    seqLength = sequence_length # S Sequence Length\n",
    "    inputSize = len(notes) - seqLength # N Samples\n",
    "    categories = 2 # C Categories\n",
    "    \n",
    "    # Yields N x S x C array\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    # We only have 2 dimensions at the moment, pitch and length\n",
    "    # noteIn - a collection of categorical arrays, each row is one category\n",
    "    # noteOut - the integer which converts to the index of that category's respective\n",
    "    # one hot encoding.  These categorical one hot encodings are later concatenated\n",
    "    # columnwise to form a multi hot encoding.\n",
    "\n",
    "    # This representation is a C x N x S array\n",
    "    \n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "\n",
    "    # Mapping of i:i+seqLength notes to note i + seqLength\n",
    "    \n",
    "    # X[0] sequence_in : [seqLength]\n",
    "    # X[1] length_in : [seqLength]\n",
    "    \n",
    "    # Y[0] sequence_out : 1\n",
    "    # Y[1] length_out : 1\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        \n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        \n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    # npatterns = len(noteIn) (inputSize)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # noteIn = np.reshape(noteIn, (inputSize, seqLength, 1))\n",
    "    \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "    \n",
    "    #print(\"noteIn shape:\")\n",
    "    #print(noteIn.shape)\n",
    "    #print(\"noteOut shape:\")\n",
    "    #print(noteOut.shape)\n",
    "    #print(noteIn)\n",
    "    \n",
    "    catNote = np_utils.to_categorical(noteOut[0])\n",
    "    catLength = np_utils.to_categorical(noteOut[1])\n",
    "    \n",
    "    # Concatenate the input arrays row wise\n",
    "    # Concatenate the categorical arrays along axis 1 (columnwise)\n",
    "    \n",
    "    #print(\"noteIn:\")\n",
    "    #print(noteIn)\n",
    "    \n",
    "    # Convert from C x N x S to N x S x C\n",
    "    \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    dout = np.concatenate((catNote, catLength), 1)\n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "    \n",
    "#     print(\"din shape:\")\n",
    "#     print(din.shape)\n",
    "#     print(\"dout shape:\")\n",
    "#     print(dout.shape)\n",
    "#     print(\"din:\")\n",
    "#     print(din)\n",
    "    \n",
    "#     print(len(catNote[0]))\n",
    "#     print(len(catLength[0]))\n",
    "    \n",
    "#     print(din[0][0][0])\n",
    "#     print(din[0][0][1])\n",
    "\n",
    "    return (din, dout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.arange(10).reshape(5,2).T.flatten())\n",
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "print(noteIn.shape)\n",
    "print(noteOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(noteIn, nvocab):\n",
    "\n",
    "#     print(\"In createNet()\")\n",
    "    \n",
    "#     print(noteIn.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    # Chris's code\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nvocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def trainNet(_epochs=1):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    nvocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "    \n",
    "    model = createNet(noteIn, nvocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(noteIn, noteOut, batch_size=1024, epochs=_epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "Parsing Music\\Fugue10.mid\n",
      "Parsing Music\\Fugue11.mid\n",
      "MIDI file Music\\Fugue12.mid failed to parse\n",
      "Parsing Music\\Fugue13.mid\n",
      "Parsing Music\\Fugue14.mid\n",
      "Parsing Music\\Fugue15.mid\n",
      "Parsing Music\\Fugue16.mid\n",
      "Parsing Music\\Fugue17.mid\n",
      "Parsing Music\\Fugue18.mid\n",
      "MIDI file Music\\Fugue19.mid failed to parse\n",
      "Parsing Music\\Fugue2.mid\n",
      "Parsing Music\\Fugue20.mid\n",
      "Parsing Music\\Fugue21.mid\n",
      "Parsing Music\\Fugue22.mid\n",
      "Parsing Music\\Fugue23.mid\n",
      "Parsing Music\\Fugue24.mid\n",
      "Parsing Music\\Fugue3.mid\n",
      "Parsing Music\\Fugue4.mid\n",
      "Parsing Music\\Fugue5.mid\n",
      "MIDI file Music\\Fugue6.mid failed to parse\n",
      "Parsing Music\\Fugue7.mid\n",
      "Parsing Music\\Fugue8.mid\n",
      "Parsing Music\\Fugue9.mid\n",
      "Instrument Parts 1\n",
      "noteIn shape:\n",
      "(2, 22374, 4)\n",
      "noteOut shape:\n",
      "(2, 22374)\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "noteIn:\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "din shape:\n",
      "(22374, 4, 2)\n",
      "dout shape:\n",
      "(22374, 114)\n",
      "din:\n",
      "[[[0.60759494 0.08571429]\n",
      "  [0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]]\n",
      "\n",
      " [[0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]]\n",
      "\n",
      " [[0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]\n",
      "  [0.87341772 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.56962025 0.02857143]\n",
      "  [0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]]\n",
      "\n",
      " [[0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]]\n",
      "\n",
      " [[0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]\n",
      "  [0.92405063 0.65714286]]]\n",
      "79\n",
      "35\n",
      "0.6075949367088608\n",
      "0.08571428571428572\n",
      "In createNet()\n",
      "(22374, 4, 2)\n",
      "Epoch 1/50\n",
      "176/350 [==============>...............] - ETA: 26s - loss: 10.1563 - accuracy: 0.0040"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-ae99f94fe298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-0fbcc36452d6>\u001b[0m in \u001b[0;36mtrainNet\u001b[1;34m(_epochs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Your line of code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoteIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoteOut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainNet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model):\n",
    "    \n",
    "    print(\"In Generate\")\n",
    "    \n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    noteLengths = pickle.load(open('noteLengths.p', 'rb'))\n",
    "\n",
    "    pitchSet = sorted(set(notes))\n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    \n",
    "    # 1. Call to prepareSeqPred\n",
    "    \n",
    "    noteIn = prepareSeqPred(notes, noteLengths) \n",
    "    \n",
    "    # print(\"Model Loaded\")\n",
    "    \n",
    "    # 2. Call to genNotes\n",
    "    \n",
    "    predOut = genNotes(model, noteIn, pitchSet, lengthSet)\n",
    "    \n",
    "    # 3. Call to createMidi\n",
    "    createMidi(predOut)\n",
    "\n",
    "# 1.\n",
    "    \n",
    "def prepareSeqPred(notes, noteLengths):\n",
    "    \n",
    "    print(\"In Prepare Sequences Prediction\")\n",
    "    \n",
    "    seqLength = sequence_length\n",
    "    inputSize = len(notes) - seqLength\n",
    "    categories = 2\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        \n",
    "        sequence_out = notes[i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        \n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "        \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "        \n",
    "#     print(\"din shape:\")\n",
    "#     print(din.shape)\n",
    "#     print(\"din:\")\n",
    "#     print(din)\n",
    "\n",
    "    return din\n",
    "\n",
    "# 2.\n",
    "\n",
    "def genNotes(model, noteIn, pitchSet, lengthSet):\n",
    "    \n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    \n",
    "    inputSize = len(noteIn)\n",
    "        \n",
    "    start = np.random.randint(0, inputSize - 1)\n",
    "    pattern = noteIn[start] # Remember that it is an N x S x C\n",
    "    \n",
    "    print(\"pattern %s\" % pattern)\n",
    "        \n",
    "    seqLength = len(pattern)\n",
    "    categories = 2\n",
    "    \n",
    "    print(\"seqLength: %d\" % seqLength)\n",
    "\n",
    "    npitches = len(pitchSet)\n",
    "    nlengths = len(lengthSet)\n",
    "    \n",
    "    print(\"npitches %d nlengths %d\" % (npitches, nlengths))\n",
    "    \n",
    "    # TODO\n",
    "    intToNote = dict((number, note) for number, note in enumerate(pitchSet))\n",
    "    intToLength = dict((number, length) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    predOut = []\n",
    "    \n",
    "#     print(\"In genNotes(): noteIn[start] = %s\" % pattern)\n",
    "#     print(\"inputSize: %d\" % inputSize)\n",
    "#     print(\"categories: %d\" % categories)\n",
    "    \n",
    "#     print(\"pitchSet %s\" % pitchSet)\n",
    "#     print(\"lengthSet %s\" % lengthSet)\n",
    "\n",
    "    for i in range(1000):\n",
    "        \n",
    "        # Reshape a single sample into 1 x S x C array\n",
    "        \n",
    "        prediction_input = np.reshape(pattern, (1, seqLength, categories))\n",
    "        \n",
    "#         print(\"prediction_input:\")\n",
    "#         print(prediction_input)\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(np.array(prediction_input))\n",
    "#         print(len(prediction[0]))       \n",
    "#         print(\"prediction: %s\" % prediction[0])\n",
    "#         print(\"prediction length: %d\" % len(prediction[0]))\n",
    "        \n",
    "        predPitch = prediction[0][:npitches].astype('float64')\n",
    "        predLength = prediction[0][npitches:].astype('float64')\n",
    "        \n",
    "#         print(\"Before\")\n",
    "#         print(predPitch)\n",
    "#         print(predLength)\n",
    "        \n",
    "        #predPitch /= sumNote\n",
    "        #predLength /= sumLength\n",
    "        \n",
    "#         print(\"sumNote %f sumLength %f\" % (predPitch.sum(), predLength.sum()))\n",
    "        \n",
    "        predPitch /= predPitch.sum()\n",
    "        predLength /= predLength.sum()\n",
    "        \n",
    "#         print(\"After\")\n",
    "#         print(predPitch)\n",
    "#         print(predLength)\n",
    "        \n",
    "#         print(\"sumNote %f sumLength %f\" % (predPitch.sum(), predLength.sum()))\n",
    "        \n",
    "        array = randm(1, predPitch)\n",
    "#         print(\"array predPitch: %s\" % array)\n",
    "        indexPitch = np.argmax(array)\n",
    "        \n",
    "        array = randm(1, predLength)\n",
    "#         print(\"array predLength: %s\" % array)\n",
    "        indexLength = np.argmax(array)\n",
    "        \n",
    "        #TODO return tuple pitch, length\n",
    "        result = np.array([intToNote[indexPitch], intToLength[indexLength]])\n",
    "        predOut.append(result)\n",
    "        \n",
    "#         print(\"result %s\" % result)\n",
    "        \n",
    "        append = np.reshape(np.array([indexPitch/float(npitches), indexLength/float(nlengths)]), (1,2))\n",
    "        pattern = np.concatenate((pattern, append))\n",
    "        \n",
    "#         print(\"pattern: %s\" % pattern)\n",
    "        \n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    print(predOut)\n",
    "\n",
    "    return predOut\n",
    "\n",
    "# 3.\n",
    "    \n",
    "def createMidi(predOut):\n",
    "    \n",
    "    print(\"In createMidi()\")\n",
    "    \n",
    "    tempo = 0.5\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in predOut:\n",
    "        if ('.' in pattern[0]) or pattern[0].isdigit():\n",
    "            notes_in_chord = pattern[0].split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if pattern[1] != '0.0':\n",
    "                    new_note.quarterLength = float(pattern[1]) # Assign duration\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern[0])\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            if pattern[1] != '0.0':\n",
    "                new_note.quarterLength = float(pattern[1]) # Assign duration\n",
    "            output_notes.append(new_note)\n",
    "        offset += tempo\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output_GAN.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: weights2-improvement-50-5.9896-bigger.hdf5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-780a52c8b1aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load a previous model (dependency)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights2-improvement-50-5.9896-bigger.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    187\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m       \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m                   (export_dir,\n\u001b[0;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: weights2-improvement-50-5.9896-bigger.hdf5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# Load a previous model (dependency)\n",
    "if model == 0:\n",
    "    model = load_model(\"weights2-improvement-50-5.9896-bigger.hdf5\")\n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_RNN (network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_network_RNN():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    n_vocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "\n",
    "    # Set up the model\n",
    "    model = create_network_RNN(noteIn, n_vocab)\n",
    "    history = History()\n",
    "    \n",
    "    # Fit the model\n",
    "    n_epochs = 11\n",
    "    model.summary()\n",
    "    model.fit(noteIn, noteOut, callbacks=[history], epochs=n_epochs, batch_size=64)\n",
    "    model.save('LSTMmodel.h5')   \n",
    "    \n",
    "    # Plot the model losses\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.savefig('LSTM_Loss_per_Epoch.png', transparent=True)\n",
    "    plt.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = train_network_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, rows, cols):\n",
    "        self.seq_length = rows\n",
    "        self.catagories = cols\n",
    "        self.seq_shape = (rows,cols,1)\n",
    "        self.latent_dim = 1000\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(512, input_shape=(self.seq_length, self.catagories), return_sequences=True))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        seq = Input(shape=(self.seq_length, self.catagories))\n",
    "        validity = model(seq)\n",
    "\n",
    "        return Model(seq, validity)\n",
    "      \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.seq_shape), activation='sigmoid'))\n",
    "        model.add(Reshape(self.seq_shape))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        seq = model(noise)\n",
    "        \n",
    "        return Model(noise, seq)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load and convert the data\n",
    "        notes, noteLengths = buildNotes()\n",
    "\n",
    "        n_vocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "        X_train, y_train = prepareSeq(notes, noteLengths)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
    "            #noise = (noise-242)/242\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "              self.disc_loss.append(d_loss[0])\n",
    "              self.gen_loss.append(g_loss)\n",
    "        \n",
    "        self.generate(notes)\n",
    "        self.plot_loss()\n",
    "        \n",
    "    def generate(self, input_notes):\n",
    "        # Get pitch names and store in a dictionary\n",
    "        notes = pickle.load(open('notes.p', 'rb'))\n",
    "        noteLengths = pickle.load(open('noteLengths.p', 'rb'))\n",
    "\n",
    "        pitchSet = sorted(set(notes))\n",
    "        lengthSet = sorted(set(noteLengths))\n",
    "        \n",
    "        npitches = len(pitchSet)\n",
    "        nlengths = len(lengthSet)\n",
    "        \n",
    "        intToNote = dict((number, note) for number, note in enumerate(pitchSet))\n",
    "        intToLength = dict((number, length) for number, length in enumerate(lengthSet))\n",
    "        \n",
    "        predOut = []\n",
    "        for i in range(25):\n",
    "            noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "            predictions = self.generator.predict(noise)\n",
    "            for pattern in predictions[0]:\n",
    "                indexPitch = int(pattern[0] * npitches)\n",
    "                indexLength = int(pattern[1] * nlengths)\n",
    "                result = np.array([intToNote[indexPitch], intToLength[indexLength]])\n",
    "                predOut.append(result)\n",
    "        createMidi(predOut)\n",
    "        \n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "Parsing Music\\Fugue10.mid\n",
      "Parsing Music\\Fugue11.mid\n",
      "MIDI file Music\\Fugue12.mid failed to parse\n",
      "Parsing Music\\Fugue13.mid\n",
      "Parsing Music\\Fugue14.mid\n",
      "Parsing Music\\Fugue15.mid\n",
      "Parsing Music\\Fugue16.mid\n",
      "Parsing Music\\Fugue17.mid\n",
      "Parsing Music\\Fugue18.mid\n",
      "MIDI file Music\\Fugue19.mid failed to parse\n",
      "Parsing Music\\Fugue2.mid\n",
      "Parsing Music\\Fugue20.mid\n",
      "Parsing Music\\Fugue21.mid\n",
      "Parsing Music\\Fugue22.mid\n",
      "Parsing Music\\Fugue23.mid\n",
      "Parsing Music\\Fugue24.mid\n",
      "Parsing Music\\Fugue3.mid\n",
      "Parsing Music\\Fugue4.mid\n",
      "Parsing Music\\Fugue5.mid\n",
      "MIDI file Music\\Fugue6.mid failed to parse\n",
      "Parsing Music\\Fugue7.mid\n",
      "Parsing Music\\Fugue8.mid\n",
      "Parsing Music\\Fugue9.mid\n",
      "Instrument Parts 1\n",
      "noteIn shape:\n",
      "(2, 22374, 4)\n",
      "noteOut shape:\n",
      "(2, 22374)\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "noteIn:\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "din shape:\n",
      "(22374, 4, 2)\n",
      "dout shape:\n",
      "(22374, 114)\n",
      "din:\n",
      "[[[0.60759494 0.08571429]\n",
      "  [0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]]\n",
      "\n",
      " [[0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]]\n",
      "\n",
      " [[0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]\n",
      "  [0.87341772 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.56962025 0.02857143]\n",
      "  [0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]]\n",
      "\n",
      " [[0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]]\n",
      "\n",
      " [[0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]\n",
      "  [0.92405063 0.65714286]]]\n",
      "79\n",
      "35\n",
      "0.6075949367088608\n",
      "0.08571428571428572\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 4, 512)            1054720   \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 1024)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,909,505\n",
      "Trainable params: 5,909,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 8)                 8200      \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 2, 1)           0         \n",
      "=================================================================\n",
      "Total params: 928,520\n",
      "Trainable params: 924,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "Parsing Music\\Fugue10.mid\n",
      "Parsing Music\\Fugue11.mid\n",
      "MIDI file Music\\Fugue12.mid failed to parse\n",
      "Parsing Music\\Fugue13.mid\n",
      "Parsing Music\\Fugue14.mid\n",
      "Parsing Music\\Fugue15.mid\n",
      "Parsing Music\\Fugue16.mid\n",
      "Parsing Music\\Fugue17.mid\n",
      "Parsing Music\\Fugue18.mid\n",
      "MIDI file Music\\Fugue19.mid failed to parse\n",
      "Parsing Music\\Fugue2.mid\n",
      "Parsing Music\\Fugue20.mid\n",
      "Parsing Music\\Fugue21.mid\n",
      "Parsing Music\\Fugue22.mid\n",
      "Parsing Music\\Fugue23.mid\n",
      "Parsing Music\\Fugue24.mid\n",
      "Parsing Music\\Fugue3.mid\n",
      "Parsing Music\\Fugue4.mid\n",
      "Parsing Music\\Fugue5.mid\n",
      "MIDI file Music\\Fugue6.mid failed to parse\n",
      "Parsing Music\\Fugue7.mid\n",
      "Parsing Music\\Fugue8.mid\n",
      "Parsing Music\\Fugue9.mid\n",
      "Instrument Parts 1\n",
      "noteIn shape:\n",
      "(2, 22374, 4)\n",
      "noteOut shape:\n",
      "(2, 22374)\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "noteIn:\n",
      "[[[0.60759494 0.67088608 0.7721519  0.87341772]\n",
      "  [0.67088608 0.7721519  0.87341772 0.97468354]\n",
      "  [0.7721519  0.87341772 0.97468354 0.87341772]\n",
      "  ...\n",
      "  [0.56962025 0.50632911 0.48101266 0.40506329]\n",
      "  [0.50632911 0.48101266 0.40506329 0.78481013]\n",
      "  [0.48101266 0.40506329 0.78481013 0.92405063]]\n",
      "\n",
      " [[0.08571429 0.08571429 0.08571429 0.14285714]\n",
      "  [0.08571429 0.08571429 0.14285714 0.        ]\n",
      "  [0.08571429 0.14285714 0.         0.        ]\n",
      "  ...\n",
      "  [0.02857143 0.02857143 0.08571429 0.02857143]\n",
      "  [0.02857143 0.08571429 0.02857143 0.65714286]\n",
      "  [0.08571429 0.02857143 0.65714286 0.65714286]]]\n",
      "din shape:\n",
      "(22374, 4, 2)\n",
      "dout shape:\n",
      "(22374, 114)\n",
      "din:\n",
      "[[[0.60759494 0.08571429]\n",
      "  [0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]]\n",
      "\n",
      " [[0.67088608 0.08571429]\n",
      "  [0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]]\n",
      "\n",
      " [[0.7721519  0.08571429]\n",
      "  [0.87341772 0.14285714]\n",
      "  [0.97468354 0.        ]\n",
      "  [0.87341772 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.56962025 0.02857143]\n",
      "  [0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]]\n",
      "\n",
      " [[0.50632911 0.02857143]\n",
      "  [0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]]\n",
      "\n",
      " [[0.48101266 0.08571429]\n",
      "  [0.40506329 0.02857143]\n",
      "  [0.78481013 0.65714286]\n",
      "  [0.92405063 0.65714286]]]\n",
      "79\n",
      "35\n",
      "0.6075949367088608\n",
      "0.08571428571428572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.698560, acc.: 48.44%] [G loss: 0.687440]\n",
      "1 [D loss: 0.687769, acc.: 50.00%] [G loss: 0.694514]\n",
      "2 [D loss: 0.681354, acc.: 78.12%] [G loss: 0.701938]\n",
      "3 [D loss: 0.672461, acc.: 87.50%] [G loss: 0.713524]\n",
      "4 [D loss: 0.660530, acc.: 93.75%] [G loss: 0.728220]\n",
      "5 [D loss: 0.638677, acc.: 96.88%] [G loss: 0.756289]\n",
      "6 [D loss: 0.612736, acc.: 92.19%] [G loss: 0.813338]\n",
      "7 [D loss: 0.579276, acc.: 89.06%] [G loss: 0.899965]\n",
      "8 [D loss: 0.530724, acc.: 87.50%] [G loss: 1.060122]\n",
      "9 [D loss: 0.496562, acc.: 85.94%] [G loss: 1.295863]\n",
      "10 [D loss: 0.463030, acc.: 85.94%] [G loss: 1.772020]\n",
      "11 [D loss: 0.313387, acc.: 95.31%] [G loss: 2.229835]\n",
      "12 [D loss: 0.402431, acc.: 85.94%] [G loss: 2.714783]\n",
      "13 [D loss: 0.281782, acc.: 89.06%] [G loss: 3.417318]\n",
      "14 [D loss: 0.305270, acc.: 90.62%] [G loss: 4.001049]\n",
      "15 [D loss: 0.312661, acc.: 89.06%] [G loss: 4.006725]\n",
      "16 [D loss: 0.363462, acc.: 90.62%] [G loss: 3.578550]\n",
      "17 [D loss: 0.456331, acc.: 85.94%] [G loss: 4.043289]\n",
      "18 [D loss: 0.253905, acc.: 93.75%] [G loss: 4.042486]\n",
      "19 [D loss: 0.307414, acc.: 87.50%] [G loss: 3.682741]\n",
      "20 [D loss: 0.332617, acc.: 89.06%] [G loss: 3.967664]\n",
      "21 [D loss: 0.404207, acc.: 82.81%] [G loss: 4.256500]\n",
      "22 [D loss: 0.455531, acc.: 79.69%] [G loss: 3.389310]\n",
      "23 [D loss: 0.250493, acc.: 92.19%] [G loss: 3.390379]\n",
      "24 [D loss: 0.308585, acc.: 89.06%] [G loss: 3.822672]\n",
      "25 [D loss: 0.124189, acc.: 98.44%] [G loss: 4.625565]\n",
      "26 [D loss: 0.374500, acc.: 82.81%] [G loss: 4.411476]\n",
      "27 [D loss: 0.364006, acc.: 85.94%] [G loss: 4.297703]\n",
      "28 [D loss: 0.309668, acc.: 90.62%] [G loss: 3.341340]\n",
      "29 [D loss: 0.430219, acc.: 87.50%] [G loss: 3.116625]\n",
      "30 [D loss: 0.329270, acc.: 89.06%] [G loss: 3.067697]\n",
      "31 [D loss: 0.178045, acc.: 95.31%] [G loss: 3.605366]\n",
      "32 [D loss: 0.212948, acc.: 93.75%] [G loss: 4.004358]\n",
      "33 [D loss: 0.262502, acc.: 92.19%] [G loss: 3.939822]\n",
      "34 [D loss: 0.135511, acc.: 96.88%] [G loss: 3.939867]\n",
      "35 [D loss: 0.296088, acc.: 89.06%] [G loss: 4.434035]\n",
      "36 [D loss: 0.298008, acc.: 87.50%] [G loss: 4.508684]\n",
      "37 [D loss: 0.309654, acc.: 90.62%] [G loss: 3.775608]\n",
      "38 [D loss: 0.476030, acc.: 81.25%] [G loss: 3.856438]\n",
      "39 [D loss: 0.226601, acc.: 92.19%] [G loss: 3.461011]\n",
      "40 [D loss: 0.346054, acc.: 85.94%] [G loss: 3.998535]\n",
      "41 [D loss: 0.300129, acc.: 92.19%] [G loss: 3.772942]\n",
      "42 [D loss: 0.185540, acc.: 95.31%] [G loss: 3.609678]\n",
      "43 [D loss: 0.307257, acc.: 90.62%] [G loss: 3.222750]\n",
      "44 [D loss: 0.277707, acc.: 89.06%] [G loss: 3.225046]\n",
      "45 [D loss: 0.201542, acc.: 93.75%] [G loss: 3.559413]\n",
      "46 [D loss: 0.130145, acc.: 96.88%] [G loss: 4.287522]\n",
      "47 [D loss: 0.249310, acc.: 89.06%] [G loss: 3.510319]\n",
      "48 [D loss: 0.347157, acc.: 85.94%] [G loss: 4.144723]\n",
      "49 [D loss: 0.394162, acc.: 81.25%] [G loss: 3.701997]\n",
      "50 [D loss: 0.358760, acc.: 89.06%] [G loss: 3.002821]\n",
      "51 [D loss: 0.176628, acc.: 96.88%] [G loss: 2.844968]\n",
      "52 [D loss: 0.283700, acc.: 90.62%] [G loss: 3.108642]\n",
      "53 [D loss: 0.380345, acc.: 82.81%] [G loss: 3.298801]\n",
      "54 [D loss: 0.271166, acc.: 87.50%] [G loss: 3.063897]\n",
      "55 [D loss: 0.245599, acc.: 92.19%] [G loss: 3.273871]\n",
      "56 [D loss: 0.284759, acc.: 87.50%] [G loss: 3.302339]\n",
      "57 [D loss: 0.230067, acc.: 90.62%] [G loss: 3.574062]\n",
      "58 [D loss: 0.292327, acc.: 89.06%] [G loss: 3.301733]\n",
      "59 [D loss: 0.174021, acc.: 95.31%] [G loss: 3.405756]\n",
      "60 [D loss: 0.169233, acc.: 92.19%] [G loss: 3.473398]\n",
      "61 [D loss: 0.143418, acc.: 95.31%] [G loss: 3.389861]\n",
      "62 [D loss: 0.287258, acc.: 90.62%] [G loss: 3.670242]\n",
      "63 [D loss: 0.418212, acc.: 81.25%] [G loss: 3.268847]\n",
      "64 [D loss: 0.195388, acc.: 92.19%] [G loss: 3.366375]\n",
      "65 [D loss: 0.155207, acc.: 93.75%] [G loss: 3.565698]\n",
      "66 [D loss: 0.121703, acc.: 96.88%] [G loss: 3.732154]\n",
      "67 [D loss: 0.206492, acc.: 90.62%] [G loss: 3.931239]\n",
      "68 [D loss: 0.155179, acc.: 93.75%] [G loss: 4.437204]\n",
      "69 [D loss: 0.141068, acc.: 95.31%] [G loss: 5.166198]\n",
      "70 [D loss: 0.315281, acc.: 90.62%] [G loss: 4.117940]\n",
      "71 [D loss: 0.223535, acc.: 89.06%] [G loss: 3.632624]\n",
      "72 [D loss: 0.341913, acc.: 85.94%] [G loss: 3.505738]\n",
      "73 [D loss: 0.216929, acc.: 90.62%] [G loss: 4.381647]\n",
      "74 [D loss: 0.366890, acc.: 81.25%] [G loss: 3.612266]\n",
      "75 [D loss: 0.373817, acc.: 84.38%] [G loss: 3.322528]\n",
      "76 [D loss: 0.308709, acc.: 87.50%] [G loss: 3.671754]\n",
      "77 [D loss: 0.281050, acc.: 89.06%] [G loss: 3.971159]\n",
      "78 [D loss: 0.272079, acc.: 92.19%] [G loss: 3.872181]\n",
      "79 [D loss: 0.448567, acc.: 81.25%] [G loss: 2.634021]\n",
      "80 [D loss: 0.205478, acc.: 93.75%] [G loss: 3.081277]\n",
      "81 [D loss: 0.365316, acc.: 84.38%] [G loss: 3.146427]\n",
      "82 [D loss: 0.243974, acc.: 90.62%] [G loss: 3.184327]\n",
      "83 [D loss: 0.379917, acc.: 82.81%] [G loss: 2.749725]\n",
      "84 [D loss: 0.190350, acc.: 92.19%] [G loss: 2.857584]\n",
      "85 [D loss: 0.193014, acc.: 90.62%] [G loss: 2.972670]\n",
      "86 [D loss: 0.408421, acc.: 82.81%] [G loss: 2.807336]\n",
      "87 [D loss: 0.207282, acc.: 92.19%] [G loss: 3.014177]\n",
      "88 [D loss: 0.344548, acc.: 82.81%] [G loss: 2.820482]\n",
      "89 [D loss: 0.185911, acc.: 92.19%] [G loss: 2.957273]\n",
      "90 [D loss: 0.188636, acc.: 92.19%] [G loss: 3.215810]\n",
      "91 [D loss: 0.404306, acc.: 82.81%] [G loss: 3.047085]\n",
      "92 [D loss: 0.231662, acc.: 90.62%] [G loss: 2.993029]\n",
      "93 [D loss: 0.305075, acc.: 87.50%] [G loss: 2.797858]\n",
      "94 [D loss: 0.234364, acc.: 93.75%] [G loss: 3.006392]\n",
      "95 [D loss: 0.367443, acc.: 85.94%] [G loss: 3.278629]\n",
      "96 [D loss: 0.271444, acc.: 89.06%] [G loss: 3.172778]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d3af4014786b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoteIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-e670db488c66>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;31m# Train the discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                                     class_weight)\n\u001b[0;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "shape = np.shape(noteIn)\n",
    "gan = GAN(rows=shape[1], cols =shape[2])    \n",
    "gan.train(epochs=500, batch_size=32, sample_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
