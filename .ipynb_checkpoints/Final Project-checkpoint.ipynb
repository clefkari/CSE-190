{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from numpy.random import multinomial as randm\n",
    "\n",
    "# Current Counts = Current Counts + Note Length % 16 ?\n",
    "\n",
    "def buildNotes():\n",
    "    \n",
    "    print(\"In buildNotes()\")\n",
    "    \n",
    "    notes = []\n",
    "    noteLengths = []\n",
    "    \n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        \n",
    "        try:\n",
    "            midi = converter.parse(file)    \n",
    "            \n",
    "        except:\n",
    "            print(\"MIDI file %s failed to parse\" % file)\n",
    "            continue\n",
    "            \n",
    "        print(\"Parsing %s\" % file)\n",
    "        notesToParse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notesToParse = s2.parts[0].recurse()\n",
    "            print(\"Instrument Parts %d\" % len(s2.parts))\n",
    "            \n",
    "        except: # file has notes in a flat structure\n",
    "            notesToParse = midi.flat.notes\n",
    "            \n",
    "        # For each note in notesToParse (a stream of notes)\n",
    "            \n",
    "        for element in notesToParse:\n",
    "            \n",
    "            # Interesting parameters of notes that we may want to look at here.\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "                \n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "\n",
    "    return notes, noteLengths\n",
    "\n",
    "def prepareSeq(notes, noteLengths):\n",
    "\n",
    "    seqLength = 4 \n",
    "\n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "\n",
    "    inputSize = len(notes) - seqLength\n",
    "    \n",
    "    noteIn = [[],[]]\n",
    "    noteOut = [[],[]]\n",
    "\n",
    "    # Mapping of seqLength notes to note i + seqLength\n",
    "    \n",
    "    # X[0] sequence_in : [seqLength]\n",
    "    # X[1] length_in : [seqLength]\n",
    "    \n",
    "    # Y[0] sequence_out : 1\n",
    "    # Y[1] length_out : 1\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        \n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        \n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "\n",
    "    # npatterns = len(noteIn) (inputSize)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # noteIn = np.reshape(noteIn, (inputSize, seqLength, 1))\n",
    "    \n",
    "    noteIn = np.array(noteIn)\n",
    "    noteOut = np.array(noteOut)\n",
    "    \n",
    "    print(noteIn.shape)\n",
    "    print(noteOut.shape)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "    \n",
    "    catNote = np_utils.to_categorical(noteOut[0])\n",
    "    catLength = np_utils.to_categorical(noteOut[1])\n",
    "    \n",
    "    # Concatenate the categorical arrays along axis 1 (columnwise)\n",
    "    \n",
    "    din = np.concatenate((noteIn[0], noteIn[1]))\n",
    "    dout = np.concatenate((catNote, catLength), 1)\n",
    "    \n",
    "    din = np.reshape(din, (len(din), seqLength, 1))\n",
    "    \n",
    "    print(dout.shape)\n",
    "    print(len(catNote[0]))\n",
    "    print(len(catLength[0]))\n",
    "\n",
    "    return (din, dout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "(2, 736, 4)\n",
      "(2, 736)\n",
      "(736, 58)\n",
      "43\n",
      "15\n",
      "(1472, 4, 1)\n",
      "(736, 58)\n"
     ]
    }
   ],
   "source": [
    "# print(np.arange(10).reshape(5,2).T.flatten())\n",
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "print(noteIn.shape)\n",
    "print(noteOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(noteIn, nvocab):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    # Chris's code\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nvocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def trainNet(_epochs=1):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    nvocab = len(set(notes))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths, nvocab)\n",
    "    \n",
    "    model = createNet(noteIn, nvocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(noteIn, noteOut, batch_size=64, epochs=_epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n",
    "def prepareSeqPred(notes, pitchnames, nvocab):\n",
    "    print(\"In Prepare Sequences Prediction\")\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    seqLength = 4\n",
    "    noteIn = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - seqLength, 1):\n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        noteIn.append([noteToInt[char] for char in sequence_in])\n",
    "        output.append(noteToInt[sequence_out])\n",
    "\n",
    "    npatterns = len(noteIn)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(noteIn, (npatterns, seqLength, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(nvocab)\n",
    "\n",
    "    return (noteIn, normalized_input)\n",
    "\n",
    "def genNotes(model, noteIn, pitchnames, nvocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(noteIn)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = noteIn[start]\n",
    "    predOut = []\n",
    "    \n",
    "    print(\"In Generate Notes: noteIn[start] = %s\" % pattern)\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(nvocab)\n",
    "\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(np.array(prediction_input))\n",
    "        \n",
    "        array = randm(1, prediction[0])\n",
    "        index = np.argmax(array)\n",
    "        \n",
    "        result = int_to_note[index]\n",
    "        predOut.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return predOut\n",
    "\n",
    "def generate():\n",
    "    print(\"In Generate\")\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    nvocab = len(set(notes))\n",
    "\n",
    "    noteIn, normalized_input = prepareSeqPred(notes, pitchnames, nvocab)\n",
    "#    model = createNet(normalized_input, nvocab)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    model = load_model(\"weights2-improvement-01-4.0703-bigger.hdf5\")\n",
    "    \n",
    "    predOut = genNotes(model, noteIn, pitchnames, nvocab)\n",
    "    createMidi(predOut)\n",
    "    \n",
    "def createMidi(predOut):\n",
    "    print(\"In Create Midi\")\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in predOut:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "Parsing Music\\Fugue10.mid\n",
      "Parsing Music\\Fugue11.mid\n",
      "MIDI file Music\\Fugue12.mid failed to parse\n",
      "Parsing Music\\Fugue13.mid\n",
      "Parsing Music\\Fugue14.mid\n",
      "Parsing Music\\Fugue15.mid\n",
      "Parsing Music\\Fugue16.mid\n",
      "Parsing Music\\Fugue17.mid\n",
      "Parsing Music\\Fugue18.mid\n",
      "MIDI file Music\\Fugue19.mid failed to parse\n",
      "Parsing Music\\Fugue2.mid\n",
      "Parsing Music\\Fugue20.mid\n",
      "Parsing Music\\Fugue21.mid\n",
      "Parsing Music\\Fugue22.mid\n",
      "Parsing Music\\Fugue23.mid\n",
      "Parsing Music\\Fugue24.mid\n",
      "Parsing Music\\Fugue3.mid\n",
      "Parsing Music\\Fugue4.mid\n",
      "Parsing Music\\Fugue5.mid\n",
      "MIDI file Music\\Fugue6.mid failed to parse\n",
      "Parsing Music\\Fugue7.mid\n",
      "Parsing Music\\Fugue8.mid\n",
      "Parsing Music\\Fugue9.mid\n",
      "Instrument Parts 1\n",
      "{'0.0': 0, '0.25': 1, '0.5': 2, '0.75': 3, '1.0': 4, '1.25': 5, '1.5': 6, '1.75': 7, '1/3': 8, '10.0': 9, '16.0': 10, '18.0': 11, '2.0': 12, '2.25': 13, '2.5': 14, '2.75': 15, '2/3': 16, '20.0': 17, '3.0': 18, '3.25': 19, '3.5': 20, '4.0': 21, '4.25': 22, '4.5': 23, '4/3': 24, '5.0': 25, '5.5': 26, '5/3': 27, '6.0': 28, '6.25': 29, '6.5': 30, '7.0': 31, '8.0': 32, '8.5': 33, '9.5': 34}\n",
      "Epoch 1/1\n",
      "22374/22374 [==============================] - 139s 6ms/step - loss: 4.0673 - acc: 0.0322\n"
     ]
    }
   ],
   "source": [
    "trainNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Generate\n",
      "In Prepare Sequences Prediction\n",
      "In Generate Notes: netIn[start] = [67, 77, 39, 75]\n",
      "['B-3', 'A4', 'G5', 'G4', 'G4', 'A4', 'G4', 'G#3', 'A4', 'A3', 'G5', 'A5', 'G4', 'F#4', '11.2', 'A4', 'G#3', 'A4', 'G4', 'G4', 'G5', 'G#3', 'D5', 'C3', 'G#5', 'A3', 'A4', 'G4', 'A4', 'A4', 'A4', 'A4', 'C3', 'D3', 'C3', 'G4', 'E-4', 'C3', 'G4', 'G4', 'G4', 'B-2', 'G4', 'A4', 'E-4', 'A4', 'A4', 'A2', 'G4', 'B-5', 'F3', 'A4', 'C#3', 'A4', 'G4', 'A4', 'G4', 'F#3', 'C#2', 'G4', 'A4', 'G#3', '8.1', 'B3', 'F3', 'A4', 'F4', 'A4', 'A4', 'B-3', 'D5', 'A4', 'C#2', 'C#2', 'C#3', 'F#3', 'F#3', 'A4', 'A4', 'F#3', 'A4', 'D3', 'A4', 'C3', 'F#3', 'D3', 'C3', 'G4', 'G4', 'G#4', 'G5', 'G5', 'C#5', 'G4', 'E-4', 'A4', 'F3', 'A4', 'C3', 'G4', 'B3', 'G4', 'G5', 'G#3', 'E-5', 'C3', 'A3', 'G4', 'A4', 'A4', 'G4', 'A4', 'A4', 'F3', 'G4', 'A2', '11.0', 'G4', 'B-2', 'F3', 'B-2', 'G4', 'G5', 'C3', 'G5', 'B-4', 'A4', 'A4', 'A4', 'A4', 'G4', 'A4', 'A4', 'F#3', 'C4', 'G5', 'C3', 'G4', 'A4', 'A3', '0', 'B-5', 'G#3', 'A4', 'A3', 'G4', 'A4', 'G4', 'D2', 'G#3', 'G4', 'A2', 'A4', 'A4', 'G4', 'G4', 'C#3', 'G4', 'B-5', 'A4', 'G4', '1.5.8', 'G5', 'A4', 'A4', 'B-4', 'A4', 'E5', 'C3', '2.6', 'A4', 'G4', 'A4', 'C#3', 'C3', 'G#3', 'A4', 'B-5', 'F#3', 'A4', 'G4', 'A4', 'F#3', 'E-4', 'E3', 'A4', 'E-2', 'G4', 'G4', 'B5', 'A4', 'G4', 'A4', 'A4', 'B4', 'G4', 'F2', 'F#3', 'A4', 'A4']\n",
      "In Create Midi\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byron's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "\n",
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    # Get notes from midi files\n",
    "    notes = buildNotes()\n",
    "\n",
    "    # Get the number of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    # Convert notes into numerical input\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    # Set up the model\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    history = History()\n",
    "    \n",
    "    # Fit the model\n",
    "    n_epochs = 2\n",
    "    model.summary()\n",
    "    model.fit(network_input, network_output, callbacks=[history], epochs=n_epochs, batch_size=64)\n",
    "    model.save('LSTMmodel.h5')\n",
    "    \n",
    "    # Use the model to generate a midi\n",
    "    prediction_output = generate_notes(model, notes, network_input, len(set(notes)))\n",
    "    create_midi(prediction_output, 'pokemon_midi')\n",
    "    \n",
    "    # Plot the model losses\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.savefig('LSTM_Loss_per_Epoch.png', transparent=True)\n",
    "    plt.close()\n",
    "  \n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input between 0 and 1\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "  \n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "    \n",
    "def generate_notes(model, notes, network_input, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = np.append(pattern,index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "  \n",
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "    \n",
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, LSTM, Bidirectional\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # Reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # Normalize input between -1 and 1\n",
    "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def generate_notes(model, network_input, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "    \n",
    "    # Get pitch names and store in a dictionary\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = numpy.append(pattern,index)\n",
    "        #pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "  \n",
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for item in prediction_output:\n",
    "        pattern = item[0]\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self, rows):\n",
    "        self.seq_length = rows\n",
    "        self.seq_shape = (self.seq_length, 1)\n",
    "        self.latent_dim = 1000\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        seq = Input(shape=self.seq_shape)\n",
    "        validity = model(seq)\n",
    "\n",
    "        return Model(seq, validity)\n",
    "      \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.seq_shape))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        seq = model(noise)\n",
    "        \n",
    "        return Model(noise, seq)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load and convert the data\n",
    "        notes = get_notes()\n",
    "        n_vocab = len(set(notes))\n",
    "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
    "            #noise = (noise-242)/242\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "              self.disc_loss.append(d_loss[0])\n",
    "              self.gen_loss.append(g_loss)\n",
    "        \n",
    "        self.generate(notes)\n",
    "        self.plot_loss()\n",
    "        \n",
    "    def generate(self, input_notes):\n",
    "        # Get pitch names and store in a dictionary\n",
    "        notes = input_notes\n",
    "        pitchnames = sorted(set(item for item in notes))\n",
    "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "        \n",
    "        # Use random noise to generate sequences\n",
    "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        predictions = self.generator.predict(noise)\n",
    "        \n",
    "        pred_notes = [x*242+242 for x in predictions[0]]\n",
    "        pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
    "        \n",
    "        create_midi(pred_notes, 'gan_final')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()\n",
    "        \n",
    "gan = GAN(rows=100)    \n",
    "gan.train(epochs=5000, batch_size=32, sample_interval=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
