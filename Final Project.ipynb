{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from numpy.random import multinomial as randm\n",
    "\n",
    "# Current Counts = Current Counts + Note Length % 16 ?\n",
    "\n",
    "def buildNotes():\n",
    "    \n",
    "    print(\"In buildNotes()\")\n",
    "    \n",
    "    notes = []\n",
    "    noteLengths = []\n",
    "    \n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        \n",
    "        try:\n",
    "            midi = converter.parse(file)    \n",
    "            \n",
    "        except:\n",
    "            print(\"MIDI file %s failed to parse\" % file)\n",
    "            continue\n",
    "            \n",
    "        print(\"Parsing %s\" % file)\n",
    "        notesToParse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notesToParse = s2.parts[0].recurse()\n",
    "            print(\"Instrument Parts %d\" % len(s2.parts))\n",
    "            \n",
    "        except: # file has notes in a flat structure\n",
    "            notesToParse = midi.flat.notes\n",
    "            \n",
    "        # For each note in notesToParse (a stream of notes)\n",
    "            \n",
    "        for element in notesToParse:\n",
    "            \n",
    "            # Interesting parameters of notes that we may want to look at here.\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "                \n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "    pickle.dump(noteLengths, open('noteLengths.p', 'wb'))\n",
    "\n",
    "    return notes, noteLengths\n",
    "\n",
    "def prepareSeq(notes, noteLengths):\n",
    "\n",
    "    seqLength = 4\n",
    "    inputSize = len(notes) - seqLength\n",
    "    categories = 2\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    # We only have 2 dimensions at the moment, pitch and length\n",
    "    # noteIn - a collection of categorical arrays, each row is one category\n",
    "    # noteOut - the integer which converts to the index of that category's respective\n",
    "    # one hot encoding.  These categorical one hot encodings are later concatenated\n",
    "    # columnwise to form a multi hot encoding.\n",
    "\n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "\n",
    "    # Mapping of i:i+seqLength notes to note i + seqLength\n",
    "    \n",
    "    # X[0] sequence_in : [seqLength]\n",
    "    # X[1] length_in : [seqLength]\n",
    "    \n",
    "    # Y[0] sequence_out : 1\n",
    "    # Y[1] length_out : 1\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        \n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        \n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    # npatterns = len(noteIn) (inputSize)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # noteIn = np.reshape(noteIn, (inputSize, seqLength, 1))\n",
    "    \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "    \n",
    "    print(\"noteIn shape:\")\n",
    "    print(noteIn.shape)\n",
    "    print(\"noteOut shape:\")\n",
    "    print(noteOut.shape)\n",
    "    print(noteIn)\n",
    "    \n",
    "    catNote = np_utils.to_categorical(noteOut[0])\n",
    "    catLength = np_utils.to_categorical(noteOut[1])\n",
    "    \n",
    "    # Concatenate the input arrays row wise\n",
    "    # Concatenate the categorical arrays along axis 1 (columnwise)\n",
    "    \n",
    "    print(\"noteIn:\")\n",
    "    print(noteIn)\n",
    "    \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    dout = np.concatenate((catNote, catLength), 1)\n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "    \n",
    "    print(\"din shape:\")\n",
    "    print(din.shape)\n",
    "    print(\"dout shape:\")\n",
    "    print(dout.shape)\n",
    "    print(\"din:\")\n",
    "    print(din)\n",
    "    \n",
    "    print(len(catNote[0]))\n",
    "    print(len(catLength[0]))\n",
    "    \n",
    "    print(din[0][0][0])\n",
    "    print(din[0][0][1])\n",
    "\n",
    "    return (din, dout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "noteIn shape:\n",
      "(2, 736, 4)\n",
      "noteOut shape:\n",
      "(2, 736)\n",
      "[[[0.46511628 0.55813953 0.65116279 0.81395349]\n",
      "  [0.55813953 0.65116279 0.81395349 0.95348837]\n",
      "  [0.65116279 0.81395349 0.95348837 0.81395349]\n",
      "  ...\n",
      "  [0.97674419 0.1627907  0.8372093  0.58139535]\n",
      "  [0.1627907  0.8372093  0.58139535 0.34883721]\n",
      "  [0.8372093  0.58139535 0.34883721 0.51162791]]\n",
      "\n",
      " [[0.13333333 0.13333333 0.13333333 0.2       ]\n",
      "  [0.13333333 0.13333333 0.2        0.        ]\n",
      "  [0.13333333 0.2        0.         0.        ]\n",
      "  ...\n",
      "  [0.06666667 0.8        0.06666667 0.13333333]\n",
      "  [0.8        0.06666667 0.13333333 0.06666667]\n",
      "  [0.06666667 0.13333333 0.06666667 0.66666667]]]\n",
      "noteIn:\n",
      "[[[0.46511628 0.55813953 0.65116279 0.81395349]\n",
      "  [0.55813953 0.65116279 0.81395349 0.95348837]\n",
      "  [0.65116279 0.81395349 0.95348837 0.81395349]\n",
      "  ...\n",
      "  [0.97674419 0.1627907  0.8372093  0.58139535]\n",
      "  [0.1627907  0.8372093  0.58139535 0.34883721]\n",
      "  [0.8372093  0.58139535 0.34883721 0.51162791]]\n",
      "\n",
      " [[0.13333333 0.13333333 0.13333333 0.2       ]\n",
      "  [0.13333333 0.13333333 0.2        0.        ]\n",
      "  [0.13333333 0.2        0.         0.        ]\n",
      "  ...\n",
      "  [0.06666667 0.8        0.06666667 0.13333333]\n",
      "  [0.8        0.06666667 0.13333333 0.06666667]\n",
      "  [0.06666667 0.13333333 0.06666667 0.66666667]]]\n",
      "din shape:\n",
      "(736, 4, 2)\n",
      "dout shape:\n",
      "(736, 58)\n",
      "din:\n",
      "[[[0.46511628 0.13333333]\n",
      "  [0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]]\n",
      "\n",
      " [[0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]]\n",
      "\n",
      " [[0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]\n",
      "  [0.81395349 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97674419 0.06666667]\n",
      "  [0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]]\n",
      "\n",
      " [[0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]]\n",
      "\n",
      " [[0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]\n",
      "  [0.51162791 0.66666667]]]\n",
      "43\n",
      "15\n",
      "0.46511627906976744\n",
      "0.13333333333333333\n",
      "(736, 4, 2)\n",
      "(736, 58)\n"
     ]
    }
   ],
   "source": [
    "# print(np.arange(10).reshape(5,2).T.flatten())\n",
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "print(noteIn.shape)\n",
    "print(noteOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(noteIn, nvocab):\n",
    "\n",
    "    print(\"In createNet()\")\n",
    "    \n",
    "    print(noteIn.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    # Chris's code\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nvocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def trainNet(_epochs=1):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    nvocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "    \n",
    "    model = createNet(noteIn, nvocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(noteIn, noteOut, batch_size=64, epochs=_epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "noteIn shape:\n",
      "(2, 736, 4)\n",
      "noteOut shape:\n",
      "(2, 736)\n",
      "[[[0.46511628 0.55813953 0.65116279 0.81395349]\n",
      "  [0.55813953 0.65116279 0.81395349 0.95348837]\n",
      "  [0.65116279 0.81395349 0.95348837 0.81395349]\n",
      "  ...\n",
      "  [0.97674419 0.1627907  0.8372093  0.58139535]\n",
      "  [0.1627907  0.8372093  0.58139535 0.34883721]\n",
      "  [0.8372093  0.58139535 0.34883721 0.51162791]]\n",
      "\n",
      " [[0.13333333 0.13333333 0.13333333 0.2       ]\n",
      "  [0.13333333 0.13333333 0.2        0.        ]\n",
      "  [0.13333333 0.2        0.         0.        ]\n",
      "  ...\n",
      "  [0.06666667 0.8        0.06666667 0.13333333]\n",
      "  [0.8        0.06666667 0.13333333 0.06666667]\n",
      "  [0.06666667 0.13333333 0.06666667 0.66666667]]]\n",
      "noteIn:\n",
      "[[[0.46511628 0.55813953 0.65116279 0.81395349]\n",
      "  [0.55813953 0.65116279 0.81395349 0.95348837]\n",
      "  [0.65116279 0.81395349 0.95348837 0.81395349]\n",
      "  ...\n",
      "  [0.97674419 0.1627907  0.8372093  0.58139535]\n",
      "  [0.1627907  0.8372093  0.58139535 0.34883721]\n",
      "  [0.8372093  0.58139535 0.34883721 0.51162791]]\n",
      "\n",
      " [[0.13333333 0.13333333 0.13333333 0.2       ]\n",
      "  [0.13333333 0.13333333 0.2        0.        ]\n",
      "  [0.13333333 0.2        0.         0.        ]\n",
      "  ...\n",
      "  [0.06666667 0.8        0.06666667 0.13333333]\n",
      "  [0.8        0.06666667 0.13333333 0.06666667]\n",
      "  [0.06666667 0.13333333 0.06666667 0.66666667]]]\n",
      "din shape:\n",
      "(736, 4, 2)\n",
      "dout shape:\n",
      "(736, 58)\n",
      "din:\n",
      "[[[0.46511628 0.13333333]\n",
      "  [0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]]\n",
      "\n",
      " [[0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]]\n",
      "\n",
      " [[0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]\n",
      "  [0.81395349 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97674419 0.06666667]\n",
      "  [0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]]\n",
      "\n",
      " [[0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]]\n",
      "\n",
      " [[0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]\n",
      "  [0.51162791 0.66666667]]]\n",
      "43\n",
      "15\n",
      "0.46511627906976744\n",
      "0.13333333333333333\n",
      "In createNet()\n",
      "(736, 4, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2638\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2639\u001b[1;33m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2640\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'lstm_1/while/mul_3' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2642\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2644\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'lstm_1/while/mul_3' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-48ef071c299e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-0fbcc36452d6>\u001b[0m in \u001b[0;36mtrainNet\u001b[1;34m(_epochs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Your line of code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoteIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoteOut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    510\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    511\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    513\u001b[0m                 updates = (self.updates +\n\u001b[0;32m    514\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3021\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m     \"\"\"\n\u001b[1;32m-> 3023\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    159\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 731\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    732\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    401\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 731\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    732\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1048\u001b[0m       math_ops.reduce_sum(gen_math_ops.mul(grad, y), rx), sx),\n\u001b[0;32m   1049\u001b[0m           array_ops.reshape(\n\u001b[1;32m-> 1050\u001b[1;33m               math_ops.reduce_sum(gen_math_ops.mul(x, grad), ry), sy))\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6876\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6878\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   6879\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3616\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3618\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2043\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2052\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2054\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mAddOp\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m   2481\u001b[0m             \u001b[0mop_input_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2483\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_AddOpInternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_AddOpInternal\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m   2502\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2504\u001b[1;33m         \u001b[0mreal_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreal_x\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_x\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m   2429\u001b[0m               \u001b[0mforward_ctxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mforward_ctxt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_context\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2431\u001b[1;33m             \u001b[0mreal_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetRealValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2432\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_external_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2433\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mGetRealValue\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1024\u001b[0m           \u001b[1;31m# Record the history of this value in forward_ctxt.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m           \u001b[0mhistory_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_grad_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddForwardAccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mAddForwardAccumulator\u001b[1;34m(self, value, dead_branch)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;31m# Make acc available in the forward context.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[0menter_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[1;31m# Add the stack_push op in the context of value.op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m             \u001b[0mis_constant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m             parallel_iterations=self._parallel_iterations)\n\u001b[0m\u001b[0;32m   2444\u001b[0m         \u001b[0menter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprevent_feeding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outer_context\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_Enter\u001b[1;34m(data, frame_name, is_constant, parallel_iterations, use_ref, use_input_shape, name)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m       result = gen_control_flow_ops.enter(\n\u001b[1;32m--> 245\u001b[1;33m           data, frame_name, is_constant, parallel_iterations, name=name)\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_input_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m       \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_control_flow_ops.py\u001b[0m in \u001b[0;36menter\u001b[1;34m(data, frame_name, is_constant, parallel_iterations, name)\u001b[0m\n\u001b[0;32m    223\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m    224\u001b[0m         \u001b[1;34m\"Enter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_constant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_constant\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                  parallel_iterations=parallel_iterations, name=name)\n\u001b[0m\u001b[0;32m    226\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3616\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3618\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 2027\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1847\u001b[0m       \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_AddInputList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m       \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_AddInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m   \u001b[1;31m# Add control inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model):\n",
    "    \n",
    "    print(\"In Generate\")\n",
    "    \n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    noteLengths = pickle.load(open('noteLengths.p', 'rb'))\n",
    "\n",
    "    pitchSet = sorted(set(notes))\n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    \n",
    "    # 1. Call to prepareSeqPred\n",
    "    \n",
    "    noteIn = prepareSeqPred(notes, noteLengths) \n",
    "    \n",
    "    # print(\"Model Loaded\")\n",
    "    \n",
    "    # 2. Call to genNotes\n",
    "    \n",
    "    predOut = genNotes(model, noteIn, pitchSet, lengthSet)\n",
    "    \n",
    "    # 3. Call to createMidi\n",
    "    createMidi(predOut)\n",
    "\n",
    "# 1.\n",
    "    \n",
    "def prepareSeqPred(notes, noteLengths):\n",
    "    \n",
    "    print(\"In Prepare Sequences Prediction\")\n",
    "    \n",
    "    seqLength = 4\n",
    "    inputSize = len(notes) - seqLength\n",
    "    categories = 2\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        \n",
    "        sequence_out = notes[i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        \n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "        \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "        \n",
    "    print(\"din shape:\")\n",
    "    print(din.shape)\n",
    "    print(\"din:\")\n",
    "    print(din)\n",
    "\n",
    "    return din\n",
    "\n",
    "# 2.\n",
    "\n",
    "def genNotes(model, noteIn, pitchSet, lengthSet):\n",
    "    \n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    \n",
    "    inputSize = len(noteIn)\n",
    "        \n",
    "    start = np.random.randint(0, inputSize - 1)\n",
    "    pattern = noteIn[start]\n",
    "    \n",
    "    print(\"pattern %s\" % pattern)\n",
    "        \n",
    "    seqLength = len(pattern)\n",
    "    categories = 2\n",
    "    \n",
    "    print(\"seqLength: %d\" % seqLength)\n",
    "\n",
    "    npitches = len(pitchSet)\n",
    "    nlengths = len(lengthSet)\n",
    "    \n",
    "    print(\"npitches %d nlengths %d\" % (npitches, nlengths))\n",
    "    \n",
    "    # TODO\n",
    "    intToNote = dict((number, note) for number, note in enumerate(pitchSet))\n",
    "    intToLength = dict((number, length) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    predOut = []\n",
    "    \n",
    "    print(\"In genNotes(): noteIn[start] = %s\" % pattern)\n",
    "    print(\"inputSize: %d\" % inputSize)\n",
    "    print(\"categories: %d\" % categories)\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        prediction_input = np.reshape(pattern, (1, seqLength, categories))\n",
    "        \n",
    "        print(\"prediction_input:\")\n",
    "        print(prediction_input)\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(np.array(prediction_input))\n",
    "        print(len(prediction[0]))\n",
    "        \n",
    "        print(\"prediction: %s\" % prediction[0])\n",
    "        \n",
    "        array = randm(1, prediction[0][:npitches])\n",
    "        indexPitch = np.argmax(array)\n",
    "        \n",
    "        sumNote = sum(prediction[0][:npitches])\n",
    "        sumLength = sum(prediction[0][npitches:])\n",
    "        \n",
    "        print(\"sumNote %f sumLength %f\" % (sumNote, sumLength))\n",
    "        \n",
    "        prediction[0][:npitches] /= sumNote\n",
    "        prediction[0][npitches:] /= sumLength\n",
    "        \n",
    "        array = randm(1, prediction[0][npitches:])\n",
    "        indexLength = np.argmax(array)\n",
    "        \n",
    "        #TODO return tuple pitch, length\n",
    "        result = np.array([intToNote[indexPitch], intToLength[indexLength]])\n",
    "        predOut.append(result)\n",
    "        \n",
    "        print(\"result %s\" % result)\n",
    "        \n",
    "        append = np.reshape(np.array([indexPitch, indexLength]), (1,2))\n",
    "        pattern = np.concatenate((pattern, append))\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return predOut\n",
    "\n",
    "# 3.\n",
    "    \n",
    "def createMidi(predOut):\n",
    "    print(\"In createMidi()\")\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in predOut:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Generate\n",
      "In Prepare Sequences Prediction\n",
      "din shape:\n",
      "(736, 4, 2)\n",
      "din:\n",
      "[[[0.46511628 0.13333333]\n",
      "  [0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]]\n",
      "\n",
      " [[0.55813953 0.13333333]\n",
      "  [0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]]\n",
      "\n",
      " [[0.65116279 0.13333333]\n",
      "  [0.81395349 0.2       ]\n",
      "  [0.95348837 0.        ]\n",
      "  [0.81395349 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97674419 0.06666667]\n",
      "  [0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]]\n",
      "\n",
      " [[0.1627907  0.8       ]\n",
      "  [0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]]\n",
      "\n",
      " [[0.8372093  0.06666667]\n",
      "  [0.58139535 0.13333333]\n",
      "  [0.34883721 0.06666667]\n",
      "  [0.51162791 0.66666667]]]\n",
      "pattern [[0.58139535 0.06666667]\n",
      " [0.48837209 0.06666667]\n",
      " [0.81395349 0.        ]\n",
      " [0.3255814  0.06666667]]\n",
      "seqLength: 4\n",
      "npitches 43 nlengths 15\n",
      "In genNotes(): noteIn[start] = [[0.58139535 0.06666667]\n",
      " [0.48837209 0.06666667]\n",
      " [0.81395349 0.        ]\n",
      " [0.3255814  0.06666667]]\n",
      "inputSize: 736\n",
      "categories: 2\n",
      "prediction_input:\n",
      "[[[0.58139535 0.06666667]\n",
      "  [0.48837209 0.06666667]\n",
      "  [0.81395349 0.        ]\n",
      "  [0.3255814  0.06666667]]]\n",
      "58\n",
      "prediction: [2.77066138e-05 1.05117824e-05 3.52835804e-02 4.96504481e-06\n",
      " 3.06466303e-04 2.59509193e-07 3.61979415e-04 2.63424776e-03\n",
      " 2.48319284e-05 6.90067900e-05 1.32436201e-01 1.00126176e-03\n",
      " 7.31226246e-05 1.34742528e-04 1.61387250e-02 9.91791952e-04\n",
      " 3.34381980e-06 4.09108936e-04 1.03656144e-03 3.16225050e-04\n",
      " 4.94991127e-06 3.18386854e-04 7.43924116e-04 1.04516300e-06\n",
      " 2.56589810e-05 7.63575613e-01 5.59906803e-05 2.14322462e-08\n",
      " 2.97902850e-04 6.07762951e-04 1.22957560e-03 1.70353986e-03\n",
      " 5.54258877e-04 1.09090666e-04 9.01243882e-04 1.02479593e-03\n",
      " 3.37885576e-04 9.98856383e-04 1.31038887e-05 1.94887128e-02\n",
      " 6.14803610e-03 1.83107017e-03 1.00823562e-03 5.60957560e-05\n",
      " 1.01276394e-03 1.19612238e-03 1.81423384e-05 4.37671270e-06\n",
      " 9.91181605e-06 1.39461772e-04 1.29796332e-03 1.29998929e-03\n",
      " 1.06571161e-03 1.83347540e-04 6.74364448e-04 7.73404492e-04\n",
      " 3.77310289e-06 2.05062297e-05]\n",
      "sumNote 0.992244 sumLength 0.007756\n",
      "result ['D5' '1/3']\n",
      "prediction_input:\n",
      "[[[ 0.48837209  0.06666667]\n",
      "  [ 0.81395349  0.        ]\n",
      "  [ 0.3255814   0.06666667]\n",
      "  [25.          8.        ]]]\n",
      "58\n",
      "prediction: [1.5815743e-29 5.3239138e-35 1.0347163e-14 0.0000000e+00 1.7817872e-25\n",
      " 0.0000000e+00 9.8554436e-03 0.0000000e+00 1.5445892e-37 9.2175428e-29\n",
      " 2.3322525e-19 2.2693035e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 6.5160996e-22 0.0000000e+00 6.0846062e-26 0.0000000e+00 3.6765386e-38\n",
      " 4.8445204e-35 9.7604042e-27 0.0000000e+00 0.0000000e+00 1.5986100e-25\n",
      " 3.5799502e-23 7.1201857e-21 0.0000000e+00 2.9351845e-02 5.5658071e-13\n",
      " 1.0899805e-29 1.1656945e-15 5.8547116e-30 2.0003374e-34 1.9498696e-09\n",
      " 7.5517583e-19 7.6396741e-25 2.7400314e-30 0.0000000e+00 7.0340699e-20\n",
      " 7.5772188e-24 2.9517288e-36 5.3229482e-24 2.2902555e-15 3.3094894e-36\n",
      " 9.6079272e-01 0.0000000e+00 3.7110398e-34 0.0000000e+00 7.3775178e-36\n",
      " 3.2261222e-14 2.8479506e-25 5.1255260e-28 3.7885457e-30 7.0409743e-26\n",
      " 4.4402635e-26 7.5705896e-20 9.9634910e-38]\n",
      "sumNote 0.039207 sumLength 0.960793\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[ 0.81395349  0.        ]\n",
      "  [ 0.3255814   0.06666667]\n",
      "  [25.          8.        ]\n",
      "  [42.          2.        ]]]\n",
      "58\n",
      "prediction: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0396054e-30 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8582115e-09 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[ 0.3255814   0.06666667]\n",
      "  [25.          8.        ]\n",
      "  [42.          2.        ]\n",
      "  [42.          2.        ]]]\n",
      "58\n",
      "prediction: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8817083e-21 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[25.  8.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 5.222511e-35 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "prediction_input:\n",
      "[[[42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]\n",
      "  [42.  2.]]]\n",
      "58\n",
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "sumNote 0.000000 sumLength 1.000000\n",
      "result ['G5' '0.5']\n",
      "In createMidi()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:143: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-23fc7c314e44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights2-improvement-01-10.7344-bigger.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-bdcb644160d5>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# 3. Call to createMidi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mcreateMidi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredOut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-bdcb644160d5>\u001b[0m in \u001b[0;36mcreateMidi\u001b[1;34m(predOut)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0moutput_notes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpattern\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredOut\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0mnotes_in_chord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mnotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "# Load a previous model (dependency)\n",
    "if model == 0:\n",
    "    model = load_model(\"weights2-improvement-01-10.7344-bigger.hdf5\")\n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
