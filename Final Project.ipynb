{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from numpy.random import multinomial as randm\n",
    "\n",
    "# Current Counts = Current Counts + Note Length % 16 ?\n",
    "\n",
    "def buildNotes():\n",
    "    \n",
    "    print(\"In buildNotes()\")\n",
    "    \n",
    "    notes = []\n",
    "    noteLengths = []\n",
    "    \n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        \n",
    "        try:\n",
    "            midi = converter.parse(file)    \n",
    "            \n",
    "        except:\n",
    "            print(\"MIDI file %s failed to parse\" % file)\n",
    "            continue\n",
    "            \n",
    "        print(\"Parsing %s\" % file)\n",
    "        notesToParse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notesToParse = s2.parts[0].recurse()\n",
    "            print(\"Instrument Parts %d\" % len(s2.parts))\n",
    "            \n",
    "        except: # file has notes in a flat structure\n",
    "            notesToParse = midi.flat.notes\n",
    "            \n",
    "        # For each note in notesToParse (a stream of notes)\n",
    "            \n",
    "        for element in notesToParse:\n",
    "            \n",
    "            # Interesting parameters of notes that we may want to look at here.\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "                \n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                noteLengths.append(str(element.quarterLength))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "\n",
    "    return notes, noteLengths\n",
    "\n",
    "def prepareSeq(notes, noteLengths):\n",
    "\n",
    "    seqLength = 4 \n",
    "\n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "\n",
    "    inputSize = len(notes) - seqLength\n",
    "    \n",
    "    noteIn = [[],[]]\n",
    "    noteOut = [[],[]]\n",
    "\n",
    "    # Mapping of seqLength notes to note i + seqLength\n",
    "    \n",
    "    # X[0] sequence_in : [seqLength]\n",
    "    # X[1] length_in : [seqLength]\n",
    "    \n",
    "    # Y[0] sequence_out : 1\n",
    "    # Y[1] length_out : 1\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        \n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        \n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "\n",
    "    # npatterns = len(noteIn) (inputSize)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # noteIn = np.reshape(noteIn, (inputSize, seqLength, 1))\n",
    "    \n",
    "    noteIn = np.array(noteIn)\n",
    "    noteOut = np.array(noteOut)\n",
    "    \n",
    "    print(noteIn.shape)\n",
    "    print(noteOut.shape)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "    \n",
    "    catNote = np_utils.to_categorical(noteOut[0])\n",
    "    catLength = np_utils.to_categorical(noteOut[1])\n",
    "    \n",
    "    # Concatenate the categorical arrays along axis 1 (columnwise)\n",
    "    \n",
    "    din = np.concatenate((noteIn[0], noteIn[1]))\n",
    "    dout = np.concatenate((catNote, catLength), 1)\n",
    "    \n",
    "    din = np.reshape(din, (len(din), seqLength, 1))\n",
    "    \n",
    "    print(dout.shape)\n",
    "    print(len(catNote[0]))\n",
    "    print(len(catLength[0]))\n",
    "\n",
    "    return (din, dout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "(2, 736, 4)\n",
      "(2, 736)\n",
      "(736, 58)\n",
      "43\n",
      "15\n",
      "(1472, 4, 1)\n",
      "(736, 58)\n"
     ]
    }
   ],
   "source": [
    "# print(np.arange(10).reshape(5,2).T.flatten())\n",
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "print(noteIn.shape)\n",
    "print(noteOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(noteIn, nvocab):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    # Chris's code\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nvocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def trainNet(_epochs=1):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    nvocab = len(set(notes))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths, nvocab)\n",
    "    \n",
    "    model = createNet(noteIn, nvocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(noteIn, noteOut, batch_size=64, epochs=_epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n",
    "def prepareSeqPred(notes, pitchnames, nvocab):\n",
    "    print(\"In Prepare Sequences Prediction\")\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    seqLength = 4\n",
    "    noteIn = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - seqLength, 1):\n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        noteIn.append([noteToInt[char] for char in sequence_in])\n",
    "        output.append(noteToInt[sequence_out])\n",
    "\n",
    "    npatterns = len(noteIn)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(noteIn, (npatterns, seqLength, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(nvocab)\n",
    "\n",
    "    return (noteIn, normalized_input)\n",
    "\n",
    "def genNotes(model, noteIn, pitchnames, nvocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(noteIn)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = noteIn[start]\n",
    "    predOut = []\n",
    "    \n",
    "    print(\"In Generate Notes: noteIn[start] = %s\" % pattern)\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(nvocab)\n",
    "\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(np.array(prediction_input))\n",
    "        \n",
    "        array = randm(1, prediction[0])\n",
    "        index = np.argmax(array)\n",
    "        \n",
    "        result = int_to_note[index]\n",
    "        predOut.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return predOut\n",
    "\n",
    "def generate():\n",
    "    print(\"In Generate\")\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    nvocab = len(set(notes))\n",
    "\n",
    "    noteIn, normalized_input = prepareSeqPred(notes, pitchnames, nvocab)\n",
    "#    model = createNet(normalized_input, nvocab)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    model = load_model(\"weights2-improvement-01-4.0703-bigger.hdf5\")\n",
    "    \n",
    "    predOut = genNotes(model, noteIn, pitchnames, nvocab)\n",
    "    createMidi(predOut)\n",
    "    \n",
    "def createMidi(predOut):\n",
    "    print(\"In Create Midi\")\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in predOut:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In buildNotes()\n",
      "Parsing Music\\Fugue1.mid\n",
      "Parsing Music\\Fugue10.mid\n",
      "Parsing Music\\Fugue11.mid\n",
      "MIDI file Music\\Fugue12.mid failed to parse\n",
      "Parsing Music\\Fugue13.mid\n",
      "Parsing Music\\Fugue14.mid\n",
      "Parsing Music\\Fugue15.mid\n",
      "Parsing Music\\Fugue16.mid\n",
      "Parsing Music\\Fugue17.mid\n",
      "Parsing Music\\Fugue18.mid\n",
      "MIDI file Music\\Fugue19.mid failed to parse\n",
      "Parsing Music\\Fugue2.mid\n",
      "Parsing Music\\Fugue20.mid\n",
      "Parsing Music\\Fugue21.mid\n",
      "Parsing Music\\Fugue22.mid\n",
      "Parsing Music\\Fugue23.mid\n",
      "Parsing Music\\Fugue24.mid\n",
      "Parsing Music\\Fugue3.mid\n",
      "Parsing Music\\Fugue4.mid\n",
      "Parsing Music\\Fugue5.mid\n",
      "MIDI file Music\\Fugue6.mid failed to parse\n",
      "Parsing Music\\Fugue7.mid\n",
      "Parsing Music\\Fugue8.mid\n",
      "Parsing Music\\Fugue9.mid\n",
      "Instrument Parts 1\n",
      "{'0.0': 0, '0.25': 1, '0.5': 2, '0.75': 3, '1.0': 4, '1.25': 5, '1.5': 6, '1.75': 7, '1/3': 8, '10.0': 9, '16.0': 10, '18.0': 11, '2.0': 12, '2.25': 13, '2.5': 14, '2.75': 15, '2/3': 16, '20.0': 17, '3.0': 18, '3.25': 19, '3.5': 20, '4.0': 21, '4.25': 22, '4.5': 23, '4/3': 24, '5.0': 25, '5.5': 26, '5/3': 27, '6.0': 28, '6.25': 29, '6.5': 30, '7.0': 31, '8.0': 32, '8.5': 33, '9.5': 34}\n",
      "Epoch 1/1\n",
      "22374/22374 [==============================] - 139s 6ms/step - loss: 4.0673 - acc: 0.0322\n"
     ]
    }
   ],
   "source": [
    "trainNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Generate\n",
      "In Prepare Sequences Prediction\n",
      "In Generate Notes: netIn[start] = [67, 77, 39, 75]\n",
      "['B-3', 'A4', 'G5', 'G4', 'G4', 'A4', 'G4', 'G#3', 'A4', 'A3', 'G5', 'A5', 'G4', 'F#4', '11.2', 'A4', 'G#3', 'A4', 'G4', 'G4', 'G5', 'G#3', 'D5', 'C3', 'G#5', 'A3', 'A4', 'G4', 'A4', 'A4', 'A4', 'A4', 'C3', 'D3', 'C3', 'G4', 'E-4', 'C3', 'G4', 'G4', 'G4', 'B-2', 'G4', 'A4', 'E-4', 'A4', 'A4', 'A2', 'G4', 'B-5', 'F3', 'A4', 'C#3', 'A4', 'G4', 'A4', 'G4', 'F#3', 'C#2', 'G4', 'A4', 'G#3', '8.1', 'B3', 'F3', 'A4', 'F4', 'A4', 'A4', 'B-3', 'D5', 'A4', 'C#2', 'C#2', 'C#3', 'F#3', 'F#3', 'A4', 'A4', 'F#3', 'A4', 'D3', 'A4', 'C3', 'F#3', 'D3', 'C3', 'G4', 'G4', 'G#4', 'G5', 'G5', 'C#5', 'G4', 'E-4', 'A4', 'F3', 'A4', 'C3', 'G4', 'B3', 'G4', 'G5', 'G#3', 'E-5', 'C3', 'A3', 'G4', 'A4', 'A4', 'G4', 'A4', 'A4', 'F3', 'G4', 'A2', '11.0', 'G4', 'B-2', 'F3', 'B-2', 'G4', 'G5', 'C3', 'G5', 'B-4', 'A4', 'A4', 'A4', 'A4', 'G4', 'A4', 'A4', 'F#3', 'C4', 'G5', 'C3', 'G4', 'A4', 'A3', '0', 'B-5', 'G#3', 'A4', 'A3', 'G4', 'A4', 'G4', 'D2', 'G#3', 'G4', 'A2', 'A4', 'A4', 'G4', 'G4', 'C#3', 'G4', 'B-5', 'A4', 'G4', '1.5.8', 'G5', 'A4', 'A4', 'B-4', 'A4', 'E5', 'C3', '2.6', 'A4', 'G4', 'A4', 'C#3', 'C3', 'G#3', 'A4', 'B-5', 'F#3', 'A4', 'G4', 'A4', 'F#3', 'E-4', 'E3', 'A4', 'E-2', 'G4', 'G4', 'B5', 'A4', 'G4', 'A4', 'A4', 'B4', 'G4', 'F2', 'F#3', 'A4', 'A4']\n",
      "In Create Midi\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
