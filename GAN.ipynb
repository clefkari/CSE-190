{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape, Dropout, LSTM, Activation, Input, Lambda, Flatten, Bidirectional\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.models import load_model\n",
    "from numpy.random import multinomial as randm\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_global = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Counts = Current Counts + Note Length % 16 ?\n",
    "\n",
    "def buildNotes():\n",
    "    \n",
    "    #print(\"In buildNotes()\")\n",
    "    \n",
    "    notes = []\n",
    "    noteLengths = []\n",
    "    \n",
    "    for file in glob.glob(\"Music/*.mid\"):\n",
    "        \n",
    "        try:\n",
    "            midi = converter.parse(file)    \n",
    "            \n",
    "        except:\n",
    "            print(\"MIDI file %s failed to parse\" % file)\n",
    "            continue\n",
    "            \n",
    "        print(\"Parsing %s\" % file)\n",
    "        notesToParse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notesToParse = s2.parts[0].recurse()\n",
    "            print(\"Instrument Parts %d\" % len(s2.parts))\n",
    "            \n",
    "        except: # file has notes in a flat structure\n",
    "            notesToParse = midi.flat.notes\n",
    "            \n",
    "        # For each note in notesToParse (a stream of notes)\n",
    "            \n",
    "        for element in notesToParse:\n",
    "            \n",
    "            # Interesting parameters of notes that we may want to look at here.\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                noteLengths.append(str(float(element.quarterLength)))\n",
    "                \n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                noteLengths.append(str(float(element.quarterLength)))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "    pickle.dump(noteLengths, open('noteLengths.p', 'wb'))\n",
    "\n",
    "    return notes, noteLengths\n",
    "\n",
    "def prepareSeq(notes, noteLengths):\n",
    "\n",
    "    seqLength = sequence_length_global # S Sequence Length\n",
    "    inputSize = len(notes) - seqLength # N Samples\n",
    "    categories = 2 # C Categories\n",
    "    \n",
    "    # Yields N x S x C array\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    # We only have 2 dimensions at the moment, pitch and length\n",
    "    # noteIn - a collection of categorical arrays, each row is one category\n",
    "    # noteOut - the integer which converts to the index of that category's respective\n",
    "    # one hot encoding.  These categorical one hot encodings are later concatenated\n",
    "    # columnwise to form a multi hot encoding.\n",
    "\n",
    "    # This representation is a C x N x S array\n",
    "    \n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "\n",
    "    # Mapping of i:i+seqLength notes to note i + seqLength\n",
    "    \n",
    "    # X[0] sequence_in : [seqLength]\n",
    "    # X[1] length_in : [seqLength]\n",
    "    \n",
    "    # Y[0] sequence_out : 1\n",
    "    # Y[1] length_out : 1\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        sequence_out = notes[i + seqLength]\n",
    "        \n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        \n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    # npatterns = len(noteIn) (inputSize)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # noteIn = np.reshape(noteIn, (inputSize, seqLength, 1))\n",
    "    \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "    \n",
    "    #print(\"noteIn shape:\")\n",
    "    #print(noteIn.shape)\n",
    "    #print(\"noteOut shape:\")\n",
    "    #print(noteOut.shape)\n",
    "    #print(noteIn)\n",
    "    \n",
    "    catNote = np_utils.to_categorical(noteOut[0])\n",
    "    catLength = np_utils.to_categorical(noteOut[1])\n",
    "    \n",
    "    # Concatenate the input arrays row wise\n",
    "    # Concatenate the categorical arrays along axis 1 (columnwise)\n",
    "    \n",
    "    #print(\"noteIn:\")\n",
    "    #print(noteIn)\n",
    "    \n",
    "    # Convert from C x N x S to N x S x C\n",
    "    \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    dout = np.concatenate((catNote, catLength), 1)\n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "    \n",
    "#     print(\"din shape:\")\n",
    "#     print(din.shape)\n",
    "#     print(\"dout shape:\")\n",
    "#     print(dout.shape)\n",
    "#     print(\"din:\")\n",
    "#     print(din)\n",
    "    \n",
    "#     print(len(catNote[0]))\n",
    "#     print(len(catLength[0]))\n",
    "    \n",
    "#     print(din[0][0][0])\n",
    "#     print(din[0][0][1])\n",
    "\n",
    "    return (din, dout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.arange(10).reshape(5,2).T.flatten())\n",
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "print(noteIn.shape)\n",
    "print(noteOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(noteIn, nvocab):\n",
    "\n",
    "#     print(\"In createNet()\")\n",
    "    \n",
    "#     print(noteIn.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    # Chris's code\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(noteIn.shape[1], noteIn.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nvocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def trainNet(_epochs=1):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    nvocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "    \n",
    "    model = createNet(noteIn, nvocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(noteIn, noteOut, batch_size=1024, epochs=_epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainNet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model):\n",
    "    \n",
    "    print(\"In Generate\")\n",
    "    \n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    noteLengths = pickle.load(open('noteLengths.p', 'rb'))\n",
    "\n",
    "    pitchSet = sorted(set(notes))\n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    \n",
    "    # 1. Call to prepareSeqPred\n",
    "    \n",
    "    noteIn = prepareSeqPred(notes, noteLengths) \n",
    "    \n",
    "    # print(\"Model Loaded\")\n",
    "    \n",
    "    # 2. Call to genNotes\n",
    "    \n",
    "    predOut = genNotes(model, noteIn, pitchSet, lengthSet)\n",
    "    \n",
    "    # 3. Call to createMidi\n",
    "    createMidi(predOut)\n",
    "\n",
    "# 1.\n",
    "    \n",
    "def prepareSeqPred(notes, noteLengths):\n",
    "    \n",
    "    print(\"In Prepare Sequences Prediction\")\n",
    "    \n",
    "    seqLength = sequence_length_global\n",
    "    inputSize = len(notes) - seqLength\n",
    "    categories = 2\n",
    "    \n",
    "    pitchSet = sorted(set(notes))\n",
    "    npitch = len(pitchSet)\n",
    "    noteToInt = dict((note, number) for number, note in enumerate(pitchSet))\n",
    "    \n",
    "    lengthSet = sorted(set(noteLengths))\n",
    "    nlengths = len(lengthSet)\n",
    "    lengthToInt = dict((length, number) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    noteIn = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    noteOut = [\n",
    "        [],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    for i in range(0, inputSize, 1):\n",
    "        \n",
    "        sequence_in = notes[i:i + seqLength]\n",
    "        length_in = noteLengths[i:i + seqLength]\n",
    "        \n",
    "        sequence_out = notes[i + seqLength]\n",
    "        length_out = noteLengths[i + seqLength]\n",
    "        \n",
    "        noteIn[0].append([noteToInt[char] for char in sequence_in])\n",
    "        noteOut[0].append(noteToInt[sequence_out])\n",
    "        \n",
    "        noteIn[1].append([lengthToInt[char] for char in length_in])\n",
    "        noteOut[1].append(lengthToInt[length_out])\n",
    "        \n",
    "    noteIn = np.array(noteIn, dtype=float)\n",
    "    noteOut = np.array(noteOut, dtype=float)\n",
    "    \n",
    "    # normalize input\n",
    "    noteIn[0] = noteIn[0] / float(npitch)\n",
    "    noteIn[1] = noteIn[1] / float(nlengths)\n",
    "        \n",
    "    reshape = []\n",
    "    for N in range(inputSize):\n",
    "        for S in range(seqLength):\n",
    "            for C in range(categories):\n",
    "                reshape.append(noteIn[C][N][S])\n",
    "    \n",
    "    din = np.reshape(reshape, (inputSize, seqLength, categories))\n",
    "        \n",
    "#     print(\"din shape:\")\n",
    "#     print(din.shape)\n",
    "#     print(\"din:\")\n",
    "#     print(din)\n",
    "\n",
    "    return din\n",
    "\n",
    "# 2.\n",
    "\n",
    "def genNotes(model, noteIn, pitchSet, lengthSet):\n",
    "    \n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    \n",
    "    inputSize = len(noteIn)\n",
    "        \n",
    "    start = np.random.randint(0, inputSize - 1)\n",
    "    pattern = noteIn[start] # Remember that it is an N x S x C\n",
    "    \n",
    "    print(\"pattern %s\" % pattern)\n",
    "        \n",
    "    seqLength = len(pattern)\n",
    "    categories = 2\n",
    "    \n",
    "    print(\"seqLength: %d\" % seqLength)\n",
    "\n",
    "    npitches = len(pitchSet)\n",
    "    nlengths = len(lengthSet)\n",
    "    \n",
    "    print(\"npitches %d nlengths %d\" % (npitches, nlengths))\n",
    "    \n",
    "    # TODO\n",
    "    intToNote = dict((number, note) for number, note in enumerate(pitchSet))\n",
    "    intToLength = dict((number, length) for number, length in enumerate(lengthSet))\n",
    "    \n",
    "    predOut = []\n",
    "    \n",
    "#     print(\"In genNotes(): noteIn[start] = %s\" % pattern)\n",
    "#     print(\"inputSize: %d\" % inputSize)\n",
    "#     print(\"categories: %d\" % categories)\n",
    "    \n",
    "#     print(\"pitchSet %s\" % pitchSet)\n",
    "#     print(\"lengthSet %s\" % lengthSet)\n",
    "\n",
    "    for i in range(1000):\n",
    "        \n",
    "        # Reshape a single sample into 1 x S x C array\n",
    "        \n",
    "        prediction_input = np.reshape(pattern, (1, seqLength, categories))\n",
    "        \n",
    "#         print(\"prediction_input:\")\n",
    "#         print(prediction_input)\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(np.array(prediction_input))\n",
    "#         print(len(prediction[0]))       \n",
    "#         print(\"prediction: %s\" % prediction[0])\n",
    "#         print(\"prediction length: %d\" % len(prediction[0]))\n",
    "        \n",
    "        predPitch = prediction[0][:npitches].astype('float64')\n",
    "        predLength = prediction[0][npitches:].astype('float64')\n",
    "        \n",
    "#         print(\"Before\")\n",
    "#         print(predPitch)\n",
    "#         print(predLength)\n",
    "        \n",
    "        #predPitch /= sumNote\n",
    "        #predLength /= sumLength\n",
    "        \n",
    "#         print(\"sumNote %f sumLength %f\" % (predPitch.sum(), predLength.sum()))\n",
    "        \n",
    "        predPitch /= predPitch.sum()\n",
    "        predLength /= predLength.sum()\n",
    "        \n",
    "#         print(\"After\")\n",
    "#         print(predPitch)\n",
    "#         print(predLength)\n",
    "        \n",
    "#         print(\"sumNote %f sumLength %f\" % (predPitch.sum(), predLength.sum()))\n",
    "        \n",
    "        array = randm(1, predPitch)\n",
    "#         print(\"array predPitch: %s\" % array)\n",
    "        indexPitch = np.argmax(array)\n",
    "        \n",
    "        array = randm(1, predLength)\n",
    "#         print(\"array predLength: %s\" % array)\n",
    "        indexLength = np.argmax(array)\n",
    "        \n",
    "        #TODO return tuple pitch, length\n",
    "        result = np.array([intToNote[indexPitch], intToLength[indexLength]])\n",
    "        predOut.append(result)\n",
    "        \n",
    "#         print(\"result %s\" % result)\n",
    "        \n",
    "        append = np.reshape(np.array([indexPitch/float(npitches), indexLength/float(nlengths)]), (1,2))\n",
    "        pattern = np.concatenate((pattern, append))\n",
    "        \n",
    "#         print(\"pattern: %s\" % pattern)\n",
    "        \n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    print(predOut)\n",
    "\n",
    "    return predOut\n",
    "\n",
    "# 3.\n",
    "    \n",
    "def createMidi(predOut):\n",
    "    \n",
    "    print(\"In createMidi()\")\n",
    "    \n",
    "    tempo = 0.5\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in predOut:\n",
    "        if ('.' in pattern[0]) or pattern[0].isdigit():\n",
    "            notes_in_chord = pattern[0].split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if pattern[1] != '0.0':\n",
    "                    new_note.quarterLength = float(pattern[1]) # Assign duration\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern[0])\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            if pattern[1] != '0.0':\n",
    "                new_note.quarterLength = float(pattern[1]) # Assign duration\n",
    "            output_notes.append(new_note)\n",
    "        offset += tempo\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output_GAN.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previous model (dependency)\n",
    "if model == 0:\n",
    "    model = load_model(\"weights2-improvement-50-5.9896-bigger.hdf5\")\n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_RNN (network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    print(network_input.shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_network_RNN():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes, noteLengths = buildNotes()\n",
    "\n",
    "    n_vocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "    noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "\n",
    "    # Set up the model\n",
    "    model = create_network_RNN(noteIn, n_vocab)\n",
    "    history = History()\n",
    "    \n",
    "    # Fit the model\n",
    "    n_epochs = 11\n",
    "    model.summary()\n",
    "    model.fit(noteIn, noteOut, callbacks=[history], epochs=n_epochs, batch_size=64)\n",
    "    model.save('LSTMmodel.h5')   \n",
    "    \n",
    "    # Plot the model losses\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.savefig('LSTM_Loss_per_Epoch.png', transparent=True)\n",
    "    plt.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = train_network_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(LSTM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, rows, cols):\n",
    "        self.seq_length = rows\n",
    "        self.catagories = cols\n",
    "        self.seq_shape = (rows,cols,1)\n",
    "        self.latent_dim = 1000\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(512, input_shape=(self.seq_length, self.catagories), return_sequences=True))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        seq = Input(shape=(self.seq_length, self.catagories))\n",
    "        validity = model(seq)\n",
    "\n",
    "        return Model(seq, validity)\n",
    "      \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNorm(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.seq_shape), activation='sigmoid'))\n",
    "        model.add(Reshape(self.seq_shape))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        seq = model(noise)\n",
    "        \n",
    "        return Model(noise, seq)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load and convert the data\n",
    "        notes, noteLengths = buildNotes()\n",
    "\n",
    "        n_vocab = len(set(notes)) + len(set(noteLengths))\n",
    "    \n",
    "        X_train, y_train = prepareSeq(notes, noteLengths)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
    "            #noise = (noise-242)/242\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "              self.disc_loss.append(d_loss[0])\n",
    "              self.gen_loss.append(g_loss)\n",
    "            \n",
    "        self.plot_loss()\n",
    "        \n",
    "    def generate(self):\n",
    "        # Get pitch names and store in a dictionary\n",
    "        notes = pickle.load(open('notes.p', 'rb'))\n",
    "        noteLengths = pickle.load(open('noteLengths.p', 'rb'))\n",
    "\n",
    "        pitchSet = sorted(set(notes))\n",
    "        lengthSet = sorted(set(noteLengths))\n",
    "        \n",
    "        npitches = len(pitchSet)\n",
    "        nlengths = len(lengthSet)\n",
    "        \n",
    "        intToNote = dict((number, note) for number, note in enumerate(pitchSet))\n",
    "        intToLength = dict((number, length) for number, length in enumerate(lengthSet))\n",
    "        \n",
    "        predOut = []\n",
    "        for i in range(10):\n",
    "            noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "            predictions = self.generator.predict(noise)\n",
    "            for pattern in predictions[0]:\n",
    "                indexPitch = int(pattern[0] * npitches)\n",
    "                indexLength = int(pattern[1] * nlengths)\n",
    "                result = np.array([intToNote[indexPitch], intToLength[indexLength]])\n",
    "                predOut.append(result)\n",
    "        createMidi(predOut)\n",
    "        \n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes, noteLengths = buildNotes()\n",
    "noteIn, noteOut = prepareSeq(notes, noteLengths)\n",
    "shape = np.shape(noteIn)\n",
    "gan = GAN(rows=shape[1], cols =shape[2])    \n",
    "gan.train(epochs=500, batch_size=32, sample_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
